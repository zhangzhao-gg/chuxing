# 初醒技术架构文档

> 构建一个轻目的陪聊系统，自动识别关键时刻并在合适时间完成情绪兑现

## 总体架构设计

### 架构层次

本系统采用四层架构设计：

1. **陪聊层** - 轻目的对话与行为数据采集
2. **关键时刻识别引擎** - 自动识别关键时刻
3. **存储系统** - 结构化存储关键时刻
4. **兑现系统** - 在合适时间完成情绪兑现

### 数据流

```
对话 → 行为抽取 → 关键时刻判断 → 结构化存储 → 调度兑现
```

## 技术架构路线图

```
用户
  ↓
陪聊层（轻目的对话）+ 语义理解 & 行为抽取层
  ↓
关键时刻识别引擎
  ↓
关键时刻结构化存储
  ↓
兑现调度引擎
  ↓
多渠道触达（电话 / 消息）
```

## 1. 陪聊层

### 功能描述

陪聊层负责与用户进行轻目的对话，同时提取行为标签和情绪信息。

### 返回数据结构

```json
{
  "chat_response": "...",
  "behavior_tags": ["meeting", "nervous"],
  "potential_moment": null,
  "emotion_level": 0-5
}
```

### 技术实现

- **对话生成**: 使用 OpenAI GPT-4o-mini/GPT-4 模型
- **上下文管理**: 滑动窗口裁剪 + 上下文压缩
- **行为抽取**: 通过 LLM 提取行为标签和情绪信息

## 2. 关键时刻识别引擎（核心壁垒）

### 功能描述

识别用户对话中的关键时刻，判断是否需要记录和提醒。

### 技术方案

采用**规则判断 + LLM 判断**的混合策略：

#### 规则层

- **触发频率**: 每一轮对话都进行规则判断
- **判断逻辑**:
  - 检测是否出现明确时间点
  - 检测是否出现明确事件（开会、提醒、通知等关键词）
  - 检测时间词、情绪词、未来导向表达
- **处理流程**:
  - 若规则匹配，携带最近上文 10 轮对话进入 LLM 进行深度判断
  - 避免重复记录关键时刻

#### LLM 层

- **触发频率**: 每隔 N 轮对话进行一次深度分析
- **判断逻辑**: 通过 LLM 分析对话上下文，识别潜在关键时刻

### 输出数据结构

```json
{
  "is_moment": true,
  "type": "event / habit / emotion",
  "time": "2026-01-12 07:30",
  "importance": "low / mid / high",
  "suggested_action": "call / message",
  "reason": "用户表达紧张"
}
```

## 3. 关键时刻结构化存储系统

### 功能描述

将识别出的关键时刻进行结构化存储，并设置定时任务。

### 数据模型

```python
Moment {
  id: str                    # 关键时刻唯一标识
  user_id: str               # 用户ID
  time: datetime             # 关键时刻时间
  event: str                 # 事件描述
  emotion: str               # 情绪标签
  importance: str            # 重要程度 (low/mid/high)
  preferred_action: str      # 建议触达方式 (call/message)
  ai_attitude: str           # AI 态度/立场
  confirmed: bool            # 是否已确认
  created_from_chat_id: str  # 来源对话ID
}
```

### 技术实现

- **数据库**: MongoDB
- **索引**: user_id, time, importance
- **定时任务**: 基于 time 字段设置触发时间

## 4. 兑现调度引擎

### 功能描述

后台轮询系统，监测到达兑现时间后执行触达动作。

### 核心功能

1. **调度即将到期关键时刻**: 轮询数据库，查找即将到期的关键时刻
2. **生成触达内容**: 根据关键时刻信息生成第一句话内容
3. **执行触达动作**: 通过电话或消息触达用户

### 技术实现

- **调度器**: 定时任务（Celery / APScheduler）
- **触达渠道**:
  - 电话: 语音合成 + 电话接口
  - 消息: 短信 / 微信 / App 推送

## 当前实现状态

### 已完成

- ✅ 陪聊层基础功能（对话生成、上下文管理）
- ✅ LLM 服务（OpenAI API 调用、上下文压缩）
- ✅ 用户管理、Agent 管理、会话管理
- ✅ 消息存储与查询
- ✅ CLI 交互式对话客户端

### 待开发

- ⏳ 行为标签提取
- ⏳ 情绪识别
- ⏳ 关键时刻识别引擎（规则层 + LLM 层）
- ⏳ 关键时刻存储系统
- ⏳ 兑现调度引擎
- ⏳ 多渠道触达（电话 / 消息）
- ⏳ 语音识别（暂缓）

## 开发计划与顺序

### 第一阶段：陪聊逻辑闭环（已完成）

- [x] FastAPI 后端服务
- [x] MongoDB 数据存储
- [x] LLM 调用与上下文管理
- [x] CLI 交互式对话

### 第二阶段：关键时刻识别

- [ ] 实现规则层判断逻辑
- [ ] 实现 LLM 层深度分析
- [ ] 设计关键时刻数据模型
- [ ] 实现关键时刻存储

### 第三阶段：兑现调度

- [ ] 实现定时调度器
- [ ] 实现触达内容生成
- [ ] 集成电话/消息触达渠道

### 第四阶段：优化与扩展

- [ ] 语音识别集成（可选）
- [ ] 多模态输入支持
- [ ] 性能优化与监控

## 技术栈

### 后端

- **语言**: Python 3.10+
- **Web 框架**: FastAPI
- **数据库**: MongoDB (motor 异步驱动)
- **LLM SDK**: OpenAI
- **Token 计算**: tiktoken

### 前端/客户端

- **CLI**: Typer + Rich
- **HTTP 客户端**: httpx

### 部署

- **容器化**: Docker
- **编排**: Docker Compose
- **包管理**: uv

## 配置参数

### LLM 配置

```bash
OPENAI_API_KEY=sk-your-key-here
OPENAI_BASE_URL=  # 可选
MAX_CONTEXT_TOKENS=4096
```

### 上下文压缩配置

```bash
ENABLE_CONTEXT_COMPRESSION=false
COMPRESSION_THRESHOLD=30
COMPRESSION_TARGET=10
```

### 数据库配置

```bash
MONGODB_URL=mongodb://localhost:27017
MONGODB_DB_NAME=llm_chat
```

## 架构设计原则

1. **单向数据流**: Router → Service → Repository → Database
2. **分层异常处理**: 不同层级抛出不同异常类型
3. **上下文即计算**: LLM 上下文运行时计算，不存储
4. **消除特殊情况**: 通过设计让边界自然融入常规
5. **异步优先**: 使用 async/await 提升性能

## 参考文档

- [产品需求文档 (PRD)](./PRD.md)
- [上下文压缩说明](./CONTEXT_COMPRESSION.md)
- [项目 README](../README.md)

---

**注意**: 文档中提到的参数和配置仅供参考，实际开发中需根据业务需求调整。
